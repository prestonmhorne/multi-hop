# config.py

# environment
RANDOM_SEED = 42
NUM_RELAYS = 7000
GUARD_FRACTION = 0.60 
EXIT_FRACTION = 0.28
MIN_BANDWIDTH = 1.0
MAX_BANDWIDTH = 500.0
MIN_LATENCY = 10.0
MAX_LATENCY = 500.0

# reward
REWARD_VALID = 0.5
REWARD_INVALID = -10.0
REWARD_BANDWIDTH_WEIGHT = 1.0
REWARD_LATENCY_WEIGHT = -0.5
REWARD_DIVERSITY_WEIGHT = 2.0

# training
DISCOUNT_FACTOR = 0.99
NUM_EPISODES = 10000
VERBOSE = True
LOG_FREQUENCY = 100

# baseline

# dqn_agent
DQN_LEARNING_RATE = 0.0001
DQN_EPSILON = 1.0
DQN_EPSILON_DECAY = 0.999
DQN_MIN_EPSILON = 0.05
DQN_BATCH_SIZE = 128
DQN_MEMORY_SIZE = 50000
DQN_TARGET_UPDATE_FREQ = 100